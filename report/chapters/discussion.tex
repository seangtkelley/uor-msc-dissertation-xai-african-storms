\chapter{Discussion}
\label{ch:discuss}
\todo{in progress}

This chapter discusses the implications of the findings, the limitations of the study, and potential directions for future research.

\section{Intensification}

\todo{basically need to talk about how the models learned to predict intensification using features which align with known physical processes but the relationships are sometimes counterintuitive, highlighting the need for careful interpretation and further investigation.}

\section{First Points Only vs All Points}

Models trained on only the first observation in each storm consistently underperform compared to those trained on all available observations. This suggests that incorporating the full temporal evolution of storms provides valuable information for prediction. 

\section{Propagation}

As shown in Tables \ref{tab:storm_direction_results} and \ref{tab:obs_experiment_results} respectively, storm direction models perform well, but models predicting the next direction and distance of the storm at an observation perform poorly. This could be due to several factors. The calculation of the next direction relies on the centroid of the storm provided by \cite{Hill2023}. For \acrshortpl{mcs}, the centroid might be weakly defined as the storm structure does not often have a clear centre of circulation compared to other systems like tropical cyclones. For example, squall lines are linear features and the centroid location outputted by the tracking algorithm may vary significantly between each time step based on the shape and orientation of the line. This would lead to particularly noisy data. To mitigate this, future work might investigate smoothing the centroid trajectory to reduce noise and improve the reliability of movement estimates. 

For direction specifically, although modifications were made to the \acrshort{rmse} function used to train and evaluate the models to account for the circular data, this still appeared to limit the capabilities of the models. Alternative approaches, such as using categorical representations of the compass bearing (i.e., N, NNE, NE, etc.) or transforming the degrees using sine and cosine functions may prove to help the models more effectively learn to predict direction. The categorical approach would be more intuitive, but would sacrifice granularity. Sine and cosine transformations likely be the optimal choice as they allow for continuous predictions. However, this would require either a multiple-output model or multiple models, thus increasing the complexity of the training process and explainability analysis. An analog for this approach would be to use the zonal and meridional speed vectors instead of distance and direction as was done in \cite{Hunt2024}. Across all these methods, the same challenges of a weakly-defined storm centroid would still apply, and an investigation into the stability of the storm tracks would be necessary.

\section{Precipitation}

It should be noted that the precipitation data has a direct relation with the predictands due to their common origin in the \acrshort{era5} data. This may lead to overfitting, as the models could learn to predict the precipitation values based on their inherent relationship with the storm characteristics rather than capturing the underlying physical processes. Indeed, we do observe that \acrshort{olr} has a high feature importance in the precipitation models, which is expected given its use in the parametrisation schemes for precipitation in \acrshort{era5} \citep{Hersbach2020}. This highlights the need for caution when interpreting the results and suggests that future work should consider incorporating independent precipitation datasets to validate the findings. For example, this thesis considered the inclusion of precipitation data from the Global Precipitation Measurement (GPM) mission, but ultimately did not include it due to over 70\% of storm observations lacking corresponding GPM data. While the universal availability of \acrshort{era5} data makes it a more practical choice for widespread application, alternative datasets would reduce interdependence between predictands and predictors, even if viable data coverage is reduced.

\section{Future Work}

\subsection{Deepening of Explainability Analysis}

Due to the limited time available for this thesis, the explainability analysis conducted was far from exhaustive. The approach of identifying candidate features for further geographic and temporal analysis using their correlation with latitude, longitude, and time was a rough heuristic which may have missed more subtle relationships within feature contributions. Future work should aim to develop more sophisticated methods or more exhaustively examine all top features if time permits.

Furthermore, the analysis primarily focused on global feature importance and summary plots. Future work could delve deeper into local explanations to understand individual predictions better. Initial candidate samples could be easily identified via predictions with anomalous \acrshort{rmse}. Special attention should be paid to instances where similar samples exist that were correctly predicted. To facilitate investigation, the SHAP library provides various visualisation tools, such as force plots and decision plots, which can be utilised to visualise which features contribute to the erroneous output. Such an approach could help identify specific conditions or feature interactions that lead to model errors, thereby guiding targeted model improvements or possibly uncovering edge-case MCS behaviour.

\subsection{Dataset Expansion and Feature Engineering}

The \acrshort{mcs} database used in this study was limited to storms which spent their entire lifecycle within the study region. Expanding the storm database to also include storms tracks that pass through the region might provide a more comprehensive dataset for analysis, especially on the edges of the domain. The dataset could also be expanded with additional features, such as equivalent potential temperature. As displayed in table \ref{tab:era5-file-patterns}, equivalent potential temperature data was available from the \acrshort{era5} data, but it was not included due to time constraints. Conversely, some features might be removed, particularly ones which contribute little to model performance, to reduce overall dimensionality and possibly improve model generalisation.

\subsection{Modelling Improvements}

Given this study focuses on post-hoc, model-agnostic explainability methods, future work could explore the integration of more complex \acrshort{ml} models, such as \acrfull{dnn}s, to potentially improve predictive performance. While these models are not inherently interpretable, the methodology of applying of SHAP to explain their predictions would remain unchanged when compared this thesis. Alternatively, more advanced, model-specific explainability techniques, such as layer-wise relevance propagation, or partially interpretable models, like attention-based \acrfull{dnn}s, could be implemented.