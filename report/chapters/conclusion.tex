\chapter{Conclusion}
\label{ch:con}

Globally, \acrfullpl{mcs} are defined as ensembles of thunderstorms organised in lines or clusters that typically produce severe weather over significant periods of time and large areas. They are a major contributor to intense rainfall \citep{Houze2004}, accounting for over 60\% of extreme rainfall events in Ethiopia and Somalia \citep{Hill2023}. Their devastating impact causes loss of life and displacement and can even impact neighbouring countries \citep{Mamo2019,Mekuria2022,Legese2020,Zaroug2014}. 

While these systems are significant in size, the convective processes that drive their intensification and propagation have historically not been directly simulated but rather parametrised in \acrfull{nwp} models \citep{Stevens2019,Yano2018,Keane2025}. Recent developments in convection-permitting models show promise in representing \acrshortpl{mcs} but forecasting inaccuracies remain prevalent \citep{Feng2025,Yano2018}. The under-representation of high-quality data in the continent of Africa further exacerbates the challenge of understanding and predicting \acrshortpl{mcs} within the region \citep{Dinku2019,Kinyondo2018,Meque2021}. Consequently, this thesis applied a reusable framework, adapted from \cite{Hunt2024}, for predicting their behaviour using \acrfull{xai} techniques. 

Prerequisite to the approach, a dataset was created to capture relevant meteorological, geographic, and temporal features along the 27,982 storm tracks within the Horn of Africa selected from \cite{Hill2023}. Multiple \acrfull{xgb} models were then trained to predict specific variables as proxies for storm intensification and propagation. The models were optimised using hyperparameter tuning and their performance compared between similar experiments with different feature sets to assess the impact of feature selection. Finally, \acrshort{shap} values were used to interrogate the models' predictions and identify the key factors influencing storm behaviour.

In experiments predicting the maximum intensity of a storm and the rate of intensification, the explainability analysis reveals that the \acrfull{ml} models learned from meteorological variables, notably \acrfull{cape}, \acrfull{tcwv}, wind shear, skin temperature, and soil moisture as expected from established literature \citep{Barton2021,Taylor2017,Li2023,Klein2020,Klein2021}. However, the feature values' influence on intensification was counter-intuitive and suggested possible spurious correlations with geography or biases within the dataset. 

Models trained to predict the overall direction of a storm were reasonably skilful, but those trained to predict direction and distance to the next observation were lacking. As such, no explainability analysis was conducted. Noisy data or suboptimal feature representation may have contributed to their poor performance. Using all available storm observations in model training also leads to better predictive capacity, rather than restricting the training dataset to only first observations. This highlights the importance of \acrshort{mcs} evolution in overall quantification of storm characteristics.

The research conducted exemplifies the potential of \acrshort{xai} techniques in understanding and interpreting the dynamics of \acrshortpl{mcs} and poses it as an informative tool for the future development of forecast systems in data-sparse regions. The methodology is generalisable across different geographies and storm types, as evidenced by its successful application to both Indian Monsoon \acrlong{lps} by \cite{Hunt2024} and \acrshortpl{mcs} in East Africa in this thesis.

\section{Future Work}
\label{sec:future-work}

\subsection{Deepening of Explainability Analysis}

The analysis primarily focused on global feature importance and summary plots. Future work could delve deeper into local explanations to understand individual predictions better. Initial candidate samples could be easily identified via predictions with anomalous \acrshort{rmse}. Special attention should be paid to instances where similar samples exist that were correctly predicted. To facilitate investigation, the SHAP library provides various visualisation tools, such as force plots and decision plots, which can be utilised to visualise which features contribute to the erroneous output. Such an approach could help identify specific conditions or feature interactions that lead to model errors, thereby guiding targeted model improvements or possibly uncovering edge-case \acrshort{mcs} behaviour.

\subsection{Dataset Expansion and Feature Engineering}

The \acrshort{mcs} database used in this study was limited to storms which spent their entire lifecycle within the study region. Expanding the storm database to also include storm tracks that pass through the region might provide a more comprehensive dataset for analysis, especially on the edges of the domain. The domain itself might also be expanded or contracted to reduce geographic correlations apparent with some of the meteorological features. For example, expansion of the dataset east to include more of the Indian Ocean or southwest to include the continuation of the Ethiopia Highlands into Kenya could improve the coverage of oceanic \acrshortpl{mcs} and reduce spatial biases with orography respectively. A reduction of the domain, perhaps to solely capture \acrshortpl{mcs} over the Ethiopian Highlands, could also help eliminate these correlations.

The dataset could also be expanded with additional features, such as equivalent potential temperature. As displayed in table \ref{tab:era5-file-patterns}, equivalent potential temperature data was available from the \acrshort{era5} data, but it was not included due to time constraints. Conversely, some features might be removed, particularly ones which contribute little to model performance, to reduce overall dimensionality and possibly improve model generalisation.

\subsection{Modelling Improvements}

Given this study focuses on post-hoc, model-agnostic explainability methods, future work could explore the integration of more complex \acrshort{ml} models, such as \acrfullpl{dnn}, to potentially improve predictive performance. While these models are not inherently interpretable, the methodology of applying of SHAP to explain their predictions would remain mostly unchanged when compared to this thesis. Alternatively, more advanced, model-specific explainability techniques, such as layer-wise relevance propagation, or partially interpretable models, like attention-based \acrshortpl{dnn}, could be implemented \citep{Zhuo2021,FurkanTekin2021}.